# scripts/predict_combined.py

import os
import json
import torch
import numpy as np
import faiss
from PIL import Image
from torchvision import models, transforms
from torchvision.datasets import ImageFolder
from torch.nn import functional as F

# ======================
# ãƒ‘ã‚¹ã®è¨­å®š
# ======================
MODEL_PATH = "../models/cnn_classifier.pth"
IMAGE_PATH = "../examples/salewa_sample.png"
TRAINING_DATA_DIR = "../training_data"
INDEX_PATH = "../data/faiss_index.index"
META_PATH = "../data/item_metadata.json"
CONFIDENCE_THRESHOLD = 0.8  # CNNã§ã®äºˆæ¸¬ç¢ºä¿¡åº¦ã®ã—ãã„å€¤

# ======================
# ã‚¯ãƒ©ã‚¹åã®å–å¾—
# ======================
dataset = ImageFolder(root=TRAINING_DATA_DIR)
classes = dataset.classes

# ======================
# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
# ======================
model = models.resnet50(weights=None)
num_ftrs = model.fc.in_features
model.fc = torch.nn.Linear(num_ftrs, len(classes))
model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
model.eval()

# ======================
# ç”»åƒã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
# ======================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
image = Image.open(IMAGE_PATH).convert("RGB")
input_tensor = transform(image).unsqueeze(0)

# ======================
# CNNã«ã‚ˆã‚‹äºˆæ¸¬
# ======================
with torch.no_grad():
    outputs = model(input_tensor)
    probs = F.softmax(outputs, dim=1)
    confidence, predicted_idx = torch.max(probs, dim=1)
    predicted_class = classes[predicted_idx.item()]
    confidence = confidence.item()

# ======================
# CNNç¢ºä¿¡åº¦ãŒé«˜ã‘ã‚Œã°æ¡ç”¨
# ======================
if confidence >= CONFIDENCE_THRESHOLD:
    print("âœ… CNNã«ã‚ˆã‚‹äºˆæ¸¬")
    print(f"ã‚¯ãƒ©ã‚¹ID: {predicted_class}")
    print(f"ç¢ºä¿¡åº¦: {confidence:.2f}")
else:
    print("ğŸ” CNNã®ç¢ºä¿¡åº¦ãŒä½ã„ãŸã‚ã€FAISSã«ã‚ˆã‚‹é¡ä¼¼æ¤œç´¢ã¸åˆ‡ã‚Šæ›¿ãˆ")

    # ResNetç‰¹å¾´æŠ½å‡ºç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€å¾Œã®fcå±¤ã‚’é™¤ãï¼‰
    feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])
    with torch.no_grad():
        features = feature_extractor(input_tensor).squeeze().numpy().astype("float32")

    # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
    index = faiss.read_index(INDEX_PATH)

    # é¡ä¼¼æ¤œç´¢
    D, I = index.search(np.array([features]), k=1)
    nearest_idx = I[0][0]

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open(META_PATH, "r", encoding="utf-8") as f:
        metadata = json.load(f)

    item = metadata[nearest_idx]
    print("âœ… FAISSã«ã‚ˆã‚‹é¡ä¼¼ã‚¢ã‚¤ãƒ†ãƒ æ¤œç´¢çµæœ")
    print(f"ã‚¢ã‚¤ãƒ†ãƒ ID: {item['id']}")
    print(f"ç”»åƒãƒ‘ã‚¹: {item['image_path']}")
