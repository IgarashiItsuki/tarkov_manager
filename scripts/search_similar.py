import os
import json
import numpy as np
from PIL import Image
from tqdm import tqdm
import faiss
import torch
import torchvision.transforms as transforms
from torchvision.models import resnet50

# === è¨­å®š ===
INPUT_IMAGE = "../examples/salewa_sample.png"  # èª¿ã¹ãŸã„ç”»åƒï¼ˆä¾‹ï¼‰
INDEX_PATH = "../data/faiss_index.index"
META_PATH = "../data/item_metadata.json"

# === ãƒ¢ãƒ‡ãƒ«æº–å‚™ ===
model = resnet50(weights="IMAGENET1K_V1")
model.eval()
model = torch.nn.Sequential(*list(model.children())[:-1])
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# === å…¥åŠ›ç”»åƒã®èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç† ===
image = Image.open(INPUT_IMAGE).convert("RGB")

# ğŸ”§ ã“ã“ã§ä¸­å¤®ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°
w, h = image.size
margin_w, margin_h = int(w * 0.15), int(h * 0.15)
image = image.crop((margin_w, margin_h, w - margin_w, h - margin_h))

# å‰å‡¦ç†ï¼ˆãƒªã‚µã‚¤ã‚º & Tensorå¤‰æ›ï¼‰
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])
input_tensor = transform(image).unsqueeze(0).to(device)

# ç‰¹å¾´é‡æŠ½å‡º
with torch.no_grad():
    feature = model(input_tensor).squeeze().cpu().numpy()
    feature = np.expand_dims(feature, axis=0).astype("float32")

# FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿
index = faiss.read_index(INDEX_PATH)

# ãƒ¡ã‚¿æƒ…å ±ã®èª­ã¿è¾¼ã¿
with open(META_PATH, "r", encoding="utf-8") as f:
    metadata = json.load(f)

# æ¤œç´¢å®Ÿè¡Œï¼ˆä¸Šä½5ä»¶ï¼‰
D, I = index.search(feature, k=5)

# çµæœè¡¨ç¤º
print("ğŸ” é¡ä¼¼ã‚¢ã‚¤ãƒ†ãƒ ï¼š")
for idx in I[0]:
    item = metadata[idx]
    print(f"- ID: {item['id']}")
    print(f"  Image: {item['image_path']}")
